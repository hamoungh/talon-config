i'm currently using talon voice recognition engine with conformer D2 model.
i'm currently happy with the quality of detecting sentences .
but when it comes to detecting the commands or individual words there is a problem.
especially i have defined all the alphabets as new commands and the commands that i use are not common english words.
for example i have configured the command 'jack' to type the alphabet   'j'. 
that was the common approach when i  used the dragon professional individual and the dragonfly library.
and i think that this is the common approach when using talon.
the reason behind it is that when people use these voice resignation software for computer programming they usually run the voice resignation in the command mode. 
but the problem that i currently have is that the accuracy of the commands especially the ones that are not rooted in english words is very low.

especially when i dictate multiple characters using commands in the same sentence.
i want you to read all the codebase and see if there is any modification that we can do to make the accuracy better.for now i don't want to implement any changes but i just want to get your ideas. give me all those ideas in a new markdown document in the conversation folder.



